{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50000 20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download = True, transform = transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download = True, transform = transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "'''\n",
    "STEP 2: MAKING DATASET ITERABLE\n",
    "'''\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 3000\n",
    "num_epochs = 20\n",
    "#num_epochs = n_iters / (len(trainset) / batch_size)\n",
    "#num_epochs = int(num_epochs)\n",
    "\n",
    "print(len(trainset), num_epochs)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True, num_workers = 2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False, num_workers = 2)\n",
    "\n",
    "'''\n",
    "STEP 3: CREATE MODEL CLASS\n",
    "'''\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolution 1\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)  \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.batchNorm1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        # Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "     \n",
    "        # Convolution 2\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.batchNorm2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Convolution 3\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.batchNorm3 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Max pool 3\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Convolution 4\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.batchNorm4 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Max pool 4\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected 1 (readout)\n",
    "        self.fc1 = nn.Linear(512, 512) \n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolution 1\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.batchNorm1(out)\n",
    "        \n",
    "        # Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        \n",
    "        # Convolution 2 \n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.batchNorm2(out)\n",
    "        \n",
    "        # Max pool 2 \n",
    "        out = self.maxpool2(out)\n",
    "\n",
    "        # Convolution 3\n",
    "        out = self.conv3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.batchNorm3(out)\n",
    "        \n",
    "        # Max pool 3\n",
    "        out = self.maxpool3(out)\n",
    "        \n",
    "    \n",
    "        # Convolution 4\n",
    "        out = self.conv4(out)\n",
    "        out = self.relu4(out)\n",
    "        out = self.batchNorm4(out)\n",
    "        \n",
    "        # Max pool 4\n",
    "        out = self.maxpool4(out)\n",
    "        \n",
    "        # Resize\n",
    "        # Original size: (100, 32, 7, 7)\n",
    "        # out.size(0): 100\n",
    "        # New out size: (100, 32*7*7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "\n",
    "        # Linear function (readout)\n",
    "        out = self.fc1(out)\n",
    "        out = self.layer(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "'''\n",
    "STEP 4: INSTANTIATE MODEL CLASS\n",
    "'''\n",
    "\n",
    "model = CNNModel().cuda()\n",
    "\n",
    "#######################\n",
    "#  USE GPU FOR MODEL  #\n",
    "#######################\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# model.to(device)\n",
    "\n",
    "'''\n",
    "STEP 5: INSTANTIATE LOSS CLASS\n",
    "'''\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "'''\n",
    "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "'''\n",
    "learning_rate = 0.0015\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.002)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 200. Loss: 1.0802453756332397. Accuracy: 54\n",
      "Iteration: 400. Loss: 1.0591685771942139. Accuracy: 61\n",
      "Iteration: 600. Loss: 1.2498900890350342. Accuracy: 63\n",
      "Iteration: 800. Loss: 0.9499179124832153. Accuracy: 68\n",
      "Iteration: 1000. Loss: 1.098762035369873. Accuracy: 70\n",
      "Iteration: 1200. Loss: 0.7513238787651062. Accuracy: 69\n",
      "Iteration: 1400. Loss: 0.84354567527771. Accuracy: 71\n",
      "Iteration: 1600. Loss: 0.5185913443565369. Accuracy: 71\n",
      "Iteration: 1800. Loss: 0.9087273478507996. Accuracy: 71\n",
      "Iteration: 2000. Loss: 0.6466696262359619. Accuracy: 73\n",
      "Iteration: 2200. Loss: 0.5459758639335632. Accuracy: 73\n",
      "Iteration: 2400. Loss: 0.6114209890365601. Accuracy: 73\n",
      "Iteration: 2600. Loss: 0.5416773557662964. Accuracy: 74\n",
      "Iteration: 2800. Loss: 0.7845168113708496. Accuracy: 74\n",
      "Iteration: 3000. Loss: 0.673625648021698. Accuracy: 75\n",
      "Iteration: 3200. Loss: 0.48281776905059814. Accuracy: 74\n",
      "Iteration: 3400. Loss: 0.6193227171897888. Accuracy: 74\n",
      "Iteration: 3600. Loss: 0.5311362743377686. Accuracy: 75\n",
      "Iteration: 3800. Loss: 0.7146061658859253. Accuracy: 73\n",
      "Iteration: 4000. Loss: 0.6406211853027344. Accuracy: 76\n",
      "Iteration: 4200. Loss: 0.4911739230155945. Accuracy: 76\n",
      "Iteration: 4400. Loss: 0.6070870161056519. Accuracy: 76\n",
      "Iteration: 4600. Loss: 0.5238867998123169. Accuracy: 76\n",
      "Iteration: 4800. Loss: 0.3915778398513794. Accuracy: 76\n",
      "Iteration: 5000. Loss: 0.5295023322105408. Accuracy: 77\n",
      "Iteration: 5200. Loss: 0.43360623717308044. Accuracy: 76\n",
      "Iteration: 5400. Loss: 0.40151968598365784. Accuracy: 77\n",
      "Iteration: 5600. Loss: 0.3985865116119385. Accuracy: 76\n",
      "Iteration: 5800. Loss: 0.6029594540596008. Accuracy: 76\n",
      "Iteration: 6000. Loss: 0.42858999967575073. Accuracy: 77\n",
      "Iteration: 6200. Loss: 0.32337379455566406. Accuracy: 78\n",
      "Iteration: 6400. Loss: 0.3180921673774719. Accuracy: 78\n",
      "Iteration: 6600. Loss: 0.32018253207206726. Accuracy: 78\n",
      "Iteration: 6800. Loss: 0.5380628705024719. Accuracy: 78\n",
      "Iteration: 7000. Loss: 0.5449371933937073. Accuracy: 78\n",
      "Iteration: 7200. Loss: 0.4668041467666626. Accuracy: 78\n",
      "Iteration: 7400. Loss: 0.3947407007217407. Accuracy: 79\n",
      "Iteration: 7600. Loss: 0.33736830949783325. Accuracy: 78\n",
      "Iteration: 7800. Loss: 0.3849654793739319. Accuracy: 78\n",
      "Iteration: 8000. Loss: 0.47112786769866943. Accuracy: 78\n",
      "Iteration: 8200. Loss: 0.38789236545562744. Accuracy: 79\n",
      "Iteration: 8400. Loss: 0.4590197503566742. Accuracy: 79\n",
      "Iteration: 8600. Loss: 0.2545468807220459. Accuracy: 79\n",
      "Iteration: 8800. Loss: 0.40812888741493225. Accuracy: 79\n",
      "Iteration: 9000. Loss: 0.35889342427253723. Accuracy: 80\n",
      "Iteration: 9200. Loss: 0.362052321434021. Accuracy: 79\n",
      "Iteration: 9400. Loss: 0.4707458019256592. Accuracy: 79\n",
      "Iteration: 9600. Loss: 0.3114205300807953. Accuracy: 80\n",
      "Iteration: 9800. Loss: 0.4438943564891815. Accuracy: 79\n",
      "Iteration: 10000. Loss: 0.4702972173690796. Accuracy: 80\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "STEP 7: TRAIN THE MODEL\n",
    "'''\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "\n",
    "        images = Variable(images).cuda()\n",
    "        labels = Variable(labels).cuda()\n",
    "        \n",
    "        # Clear gradients w.r.t. parameters\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass to get output/logits\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate Loss: softmax --> cross entropy loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        \n",
    "        # Updating parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        iter += 1\n",
    "        \n",
    "        if iter % 200 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in testloader:\n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                #images = Variable(images).to(device)\n",
    "                #labels = Variable(labels).to(device)\n",
    "                images = Variable(images).cuda()\n",
    "                labels = Variable(labels).cuda()\n",
    "                \n",
    "                # Forward pass only to get logits/output\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                #######################\n",
    "                #  USE GPU FOR MODEL  #\n",
    "                #######################\n",
    "                # Total correct predictions\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / total\n",
    "            \n",
    "            # Print Loss\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
